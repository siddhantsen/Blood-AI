{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce0eb697-af00-429e-a3e2-eece4af1a49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models import NodeConfig\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import argparse\n",
    "from pytorch_tabular.models import FTTransformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e71d8a-054b-4091-8233-634d94b008cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(r\"C:\\Users\\joshu\\train_imputed.xlsx\", index_col = \"Unnamed: 0\")\n",
    "df_val = pd.read_excel(r\"C:\\Users\\joshu\\train_imputed.xlsx\", index_col = \"Unnamed: 0\")\n",
    "df_test = pd.read_excel(r\"C:\\Users\\joshu\\test_imputed.xlsx\", index_col = \"Unnamed: 0\")\n",
    "\n",
    "labs = {\n",
    "    \"51221\": \"Hematocrit\",\n",
    "    \"51265\": \"Platelet Count\",\n",
    "    \"50912\": \"Creatinine\",\n",
    "    \"50971\": \"Potassium\",\n",
    "    \"51222\": \"Hemoglobin\",\n",
    "    \"51301\": \"White Blood Cells\",\n",
    "    \"51249\": \"MCHC\",\n",
    "    \"51279\": \"Red Blood Cells\",\n",
    "    \"51250\": \"MCV\",\n",
    "    \"51248\": \"MCH\",\n",
    "    \"51277\": \"RDW\",\n",
    "    \"51006\": \"Urea Nitrogen\",\n",
    "    \"50983\": \"Sodium\",\n",
    "    \"50902\": \"Chloride\",\n",
    "    \"50882\": \"Bicarbonate\",\n",
    "    \"50868\": \"Anion Gap\",\n",
    "    \"50931\": \"Glucose\",\n",
    "    \"50960\": \"Magnesium\",\n",
    "    \"50893\": \"Calcium, Total\",\n",
    "    \"50970\": \"Phosphate\",\n",
    "    \"51237\": \"INR(PT)\",\n",
    "    \"51274\": \"PT\",\n",
    "    \"51275\": \"PTT\",\n",
    "    \"51146\": \"Basophils\",\n",
    "    \"51256\": \"Neutrophils\",\n",
    "    \"51254\": \"Monocytes\",\n",
    "    \"51200\": \"Eosinophils\",\n",
    "    \"51244\": \"Lymphocytes\",\n",
    "    \"52172\": \"RDW-SD\",\n",
    "    \"50934\": \"H\",\n",
    "    \"51678\": \"L\",\n",
    "    \"50947\": \"I\",\n",
    "    \"50861\": \"Alanine Aminotransferase (ALT)\",\n",
    "    \"50878\": \"Asparate Aminotransferase (AST)\",\n",
    "    \"50813\": \"Lactate\",\n",
    "    \"50863\": \"Alkaline Phosphatase\",\n",
    "    \"50885\": \"Bilirubin, Total\",\n",
    "    \"50820\": \"pH\",\n",
    "    \"50862\": \"Albumin\",\n",
    "    \"50802\": \"Base Excess\",\n",
    "    \"50821\": \"pO2\",\n",
    "    \"50804\": \"Calculated Total CO2\",\n",
    "    \"50818\": \"pCO2\",\n",
    "    \"52075\": \"Absolute Neutrophil Count\",\n",
    "    \"52073\": \"Absolute Eosinophil Count\",\n",
    "    \"52074\": \"Absolute Monocyte Count\",\n",
    "    \"52069\": \"Absolute Basophil Count\",\n",
    "    \"51133\": \"Absolute Lymphocyte Count\",\n",
    "    \"50910\": \"Creatine Kinase (CK)\",\n",
    "    \"52135\": \"Immature Granulocytes\"\n",
    "}\n",
    "labs_reversed = {value: key for key, value in labs.items()}\n",
    "\n",
    "total_feats = ['Hematocrit',\n",
    " 'PTT',\n",
    " 'Asparate Aminotransferase (AST)',\n",
    " 'Chloride',\n",
    " 'White Blood Cells',\n",
    " 'Potassium',\n",
    " 'Calcium, Total',\n",
    " 'Phosphate',\n",
    " 'Monocytes',\n",
    " 'Eosinophils',\n",
    " 'Urea Nitrogen',\n",
    " 'pH',\n",
    " 'pCO2']\n",
    "\n",
    "encode = lambda x: [labs_reversed[i] for i in x]\n",
    "decode = lambda x: [labs[i] for i in x]\n",
    "\n",
    "cols = decode(df_train.columns.to_list())\n",
    "targets = list(set(cols) - set(total_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29638d7c-8f4b-4065-a29e-eb4eef2be0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(df_train[encode(total_feats)].values).type(torch.float)\n",
    "Y_train = torch.tensor(df_train[encode(targets)].values).type(torch.float)\n",
    "\n",
    "Y_test =  torch.tensor(df_test[encode(targets)].values).type(torch.float)\n",
    "X_test =  torch.tensor(df_test[encode(total_feats)].values).type(torch.float)\n",
    "\n",
    "X_val = torch.tensor(df_val[encode(total_feats)].values).type(torch.float)\n",
    "Y_val = torch.tensor(df_val[encode(targets)].values).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4821e6f8-1347-4b67-9b80-f0b544d147f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credits to Yandex https://github.com/Qwicen/node/blob/master/lib/nn_utils.py\n",
    "def _make_ix_like(input, dim=0):\n",
    "    d = input.size(dim)\n",
    "    rho = torch.arange(1, d + 1, device=input.device, dtype=input.dtype)\n",
    "    view = [1] * input.dim()\n",
    "    view[0] = -1\n",
    "    return rho.view(view).transpose(0, dim)\n",
    "\n",
    "\n",
    "class SparsemaxFunction(Function):\n",
    "    \"\"\"\n",
    "    An implementation of sparsemax (Martins & Astudillo, 2016). See\n",
    "    :cite:`DBLP:journals/corr/MartinsA16` for detailed description.\n",
    "    By Ben Peters and Vlad Niculae\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, dim=-1):\n",
    "        \"\"\"sparsemax: normalizing sparse transform (a la softmax)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ctx : torch.autograd.function._ContextMethodMixin\n",
    "        input : torch.Tensor\n",
    "            any shape\n",
    "        dim : int\n",
    "            dimension along which to apply sparsemax\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output : torch.Tensor\n",
    "            same shape as input\n",
    "\n",
    "        \"\"\"\n",
    "        ctx.dim = dim\n",
    "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
    "        input -= max_val  # same numerical stability trick as for softmax\n",
    "        tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n",
    "        output = torch.clamp(input - tau, min=0)\n",
    "        ctx.save_for_backward(supp_size, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        supp_size, output = ctx.saved_tensors\n",
    "        dim = ctx.dim\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[output == 0] = 0\n",
    "\n",
    "        v_hat = grad_input.sum(dim=dim) / supp_size.to(output.dtype).squeeze()\n",
    "        v_hat = v_hat.unsqueeze(dim)\n",
    "        grad_input = torch.where(output != 0, grad_input - v_hat, grad_input)\n",
    "        return grad_input, None\n",
    "\n",
    "    @staticmethod\n",
    "    def _threshold_and_support(input, dim=-1):\n",
    "        \"\"\"Sparsemax building block: compute the threshold\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input: torch.Tensor\n",
    "            any dimension\n",
    "        dim : int\n",
    "            dimension along which to apply the sparsemax\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tau : torch.Tensor\n",
    "            the threshold value\n",
    "        support_size : torch.Tensor\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        input_srt, _ = torch.sort(input, descending=True, dim=dim)\n",
    "        input_cumsum = input_srt.cumsum(dim) - 1\n",
    "        rhos = _make_ix_like(input, dim)\n",
    "        support = rhos * input_srt > input_cumsum\n",
    "\n",
    "        support_size = support.sum(dim=dim).unsqueeze(dim)\n",
    "        tau = input_cumsum.gather(dim, support_size - 1)\n",
    "        tau /= support_size.to(input.dtype)\n",
    "        return tau, support_size\n",
    "\n",
    "\n",
    "sparsemax = SparsemaxFunction.apply\n",
    "\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=-1):\n",
    "        self.dim = dim\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return sparsemax(input, self.dim)\n",
    "\n",
    "\n",
    "class Entmax15Function(Function):\n",
    "    \"\"\"\n",
    "    An implementation of exact Entmax with alpha=1.5 (B. Peters, V. Niculae, A. Martins). See\n",
    "    :cite:`https://arxiv.org/abs/1905.05702 for detailed description.\n",
    "    Source: https://github.com/deep-spin/entmax\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, dim=-1):\n",
    "        ctx.dim = dim\n",
    "\n",
    "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
    "        input = input - max_val  # same numerical stability trick as for softmax\n",
    "        input = input / 2  # divide by 2 to solve actual Entmax\n",
    "\n",
    "        tau_star, _ = Entmax15Function._threshold_and_support(input, dim)\n",
    "        output = torch.clamp(input - tau_star, min=0) ** 2\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        Y, = ctx.saved_tensors\n",
    "        gppr = Y.sqrt()  # = 1 / g'' (Y)\n",
    "        dX = grad_output * gppr\n",
    "        q = dX.sum(ctx.dim) / gppr.sum(ctx.dim)\n",
    "        q = q.unsqueeze(ctx.dim)\n",
    "        dX -= q * gppr\n",
    "        return dX, None\n",
    "\n",
    "    @staticmethod\n",
    "    def _threshold_and_support(input, dim=-1):\n",
    "        Xsrt, _ = torch.sort(input, descending=True, dim=dim)\n",
    "\n",
    "        rho = _make_ix_like(input, dim)\n",
    "        mean = Xsrt.cumsum(dim) / rho\n",
    "        mean_sq = (Xsrt ** 2).cumsum(dim) / rho\n",
    "        ss = rho * (mean_sq - mean ** 2)\n",
    "        delta = (1 - ss) / rho\n",
    "\n",
    "        # NOTE this is not exactly the same as in reference algo\n",
    "        # Fortunately it seems the clamped values never wrongly\n",
    "        # get selected by tau <= sorted_z. Prove this!\n",
    "        delta_nz = torch.clamp(delta, 0)\n",
    "        tau = mean - torch.sqrt(delta_nz)\n",
    "\n",
    "        support_size = (tau <= Xsrt).sum(dim).unsqueeze(dim)\n",
    "        tau_star = tau.gather(dim, support_size - 1)\n",
    "        return tau_star, support_size\n",
    "\n",
    "\n",
    "class Entmoid15(Function):\n",
    "    \"\"\" A highly optimized equivalent of lambda x: Entmax15([x, 0]) \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = Entmoid15._forward(input)\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _forward(input):\n",
    "        input, is_pos = abs(input), input >= 0\n",
    "        tau = (input + torch.sqrt(F.relu(8 - input ** 2))) / 2\n",
    "        tau.masked_fill_(tau <= input, 2.0)\n",
    "        y_neg = 0.25 * F.relu(tau - input, inplace=True) ** 2\n",
    "        return torch.where(is_pos, 1 - y_neg, y_neg)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return Entmoid15._backward(ctx.saved_tensors[0], grad_output)\n",
    "\n",
    "    @staticmethod\n",
    "    def _backward(output, grad_output):\n",
    "        gppr0, gppr1 = output.sqrt(), (1 - output).sqrt()\n",
    "        grad_input = grad_output * gppr0\n",
    "        q = grad_input / (gppr0 + gppr1)\n",
    "        grad_input -= q * gppr0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "entmax15 = Entmax15Function.apply\n",
    "entmoid15 = Entmoid15.apply\n",
    "\n",
    "\n",
    "class Entmax15(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=-1):\n",
    "        self.dim = dim\n",
    "        super(Entmax15, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return entmax15(input, self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4068a732-c297-4547-887c-40cffcc6fc94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_glu(module, input_dim, output_dim):\n",
    "    gain_value = np.sqrt((input_dim + output_dim) / np.sqrt(input_dim))\n",
    "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
    "    return\n",
    "\n",
    "class GBN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Ghost Batch Normalization\n",
    "    https://arxiv.org/abs/1705.08741\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, virtual_batch_size=512):\n",
    "        super(GBN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.bn = nn.BatchNorm1d(self.input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training == True:\n",
    "            chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
    "            res = [self.bn(x_) for x_ in chunks]\n",
    "            return torch.cat(res, dim=0)\n",
    "        else:\n",
    "            return self.bn(x)\n",
    "\n",
    "class LearnableLocality(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, k):\n",
    "        super(LearnableLocality, self).__init__()\n",
    "        self.register_parameter('weight', nn.Parameter(torch.rand(k, input_dim)))\n",
    "        self.smax = Entmax15(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = self.smax(self.weight)\n",
    "        masked_x = torch.einsum('nd,bd->bnd', mask, x)  # [B, k, D]\n",
    "        return masked_x\n",
    "\n",
    "class AbstractLayer(nn.Module):\n",
    "    def __init__(self, base_input_dim, base_output_dim, k, virtual_batch_size, bias=True):\n",
    "        super(AbstractLayer, self).__init__()\n",
    "        self.masker = LearnableLocality(input_dim=base_input_dim, k=k)\n",
    "        self.fc = nn.Conv1d(base_input_dim * k, 2 * k * base_output_dim, kernel_size=1, groups=k, bias=bias)\n",
    "        initialize_glu(self.fc, input_dim=base_input_dim * k, output_dim=2 * k * base_output_dim)\n",
    "        self.bn = GBN(2 * base_output_dim * k, virtual_batch_size)\n",
    "        self.k = k\n",
    "        self.base_output_dim = base_output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x.size(0)\n",
    "        x = self.masker(x)  # [B, D] -> [B, k, D]\n",
    "        x = self.fc(x.view(b, -1, 1))  # [B, k, D] -> [B, k * D, 1] -> [B, k * (2 * D'), 1]\n",
    "        x = self.bn(x)\n",
    "        chunks = x.chunk(self.k, 1)  # k * [B, 2 * D', 1]\n",
    "        x = sum([F.relu(torch.sigmoid(x_[:, :self.base_output_dim, :]) * x_[:, self.base_output_dim:, :]) for x_ in chunks])  # k * [B, D', 1] -> [B, D', 1]\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, base_outdim, k, virtual_batch_size, fix_input_dim, drop_rate):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = AbstractLayer(input_dim, base_outdim // 2, k, virtual_batch_size)\n",
    "        self.conv2 = AbstractLayer(base_outdim // 2, base_outdim, k, virtual_batch_size)\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            AbstractLayer(fix_input_dim, base_outdim, k, virtual_batch_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pre_out=None):\n",
    "        if pre_out == None:\n",
    "            pre_out = x\n",
    "        out = self.conv1(pre_out)\n",
    "        out = self.conv2(out)\n",
    "        identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return F.leaky_relu(out, 0.01)\n",
    "\n",
    "\n",
    "class DANet(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, layer_num, base_outdim, k, virtual_batch_size, drop_rate=0.1):\n",
    "        super(DANet, self).__init__()\n",
    "        params = {'base_outdim': base_outdim, 'k': k, 'virtual_batch_size': virtual_batch_size,\n",
    "                  'fix_input_dim': input_dim, 'drop_rate': drop_rate}\n",
    "        self.init_layer = BasicBlock(input_dim, **params)\n",
    "        self.lay_num = layer_num\n",
    "        self.layer = nn.ModuleList()\n",
    "        for i in range((layer_num // 2) - 1):\n",
    "            self.layer.append(BasicBlock(base_outdim, **params))\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(base_outdim, 256),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(256, 512),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(512, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.init_layer(x)\n",
    "        for i in range(len(self.layer)):\n",
    "            out = self.layer[i](x, out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3447ed-a055-4d80-b492-5d915cd1d7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(torchvision.ops.MLP):\n",
    "    \n",
    "    def __init__(self, in_channels, hidden_channels, norm_layer, activation_layer, bias, dropout):\n",
    "        \n",
    "        super().__init__(in_channels, hidden_channels, norm_layer, activation_layer, bias, dropout)\n",
    "        \n",
    "    def train(self, X_train, Y_train, iters=1000, lr=0.001, verbose=False):\n",
    "        \n",
    "        loss_f = nn.MSELoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        for step in range(iters):\n",
    "\n",
    "            y_preds = self(X_train)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_f(y_preds, Y_train)\n",
    "            \n",
    "            if step%100 == 0 and verbose:\n",
    "        \n",
    "                print(f\"train loss: {loss.item()}\")\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332043b5-49c4-423b-83be-5c8f869322ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.588984489440918\n",
      "train loss: 0.04886932298541069\n",
      "train loss: 0.041369207203388214\n"
     ]
    }
   ],
   "source": [
    "in_channels = len(total_feats)\n",
    "\n",
    "out_dim =  len(targets)\n",
    "\n",
    "hidden_channels = [125]*11 + [out_dim]\n",
    "\n",
    "norm_layer = nn.LayerNorm\n",
    "\n",
    "activation_layer = nn.ReLU\n",
    "\n",
    "bias = True\n",
    "\n",
    "dropout = 0.189\n",
    "    \n",
    "mlp = MLP(in_channels=in_channels,hidden_channels=hidden_channels,\n",
    "                         norm_layer=norm_layer,activation_layer=activation_layer, bias=bias, dropout=dropout)\n",
    "mlp.train(X_train, Y_train, lr=0.000418, verbose=True, iters=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb031e6-3858-4e3f-8629-80d4850858bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">825</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:21:25\u001b[0m,\u001b[1;36m825\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m171\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">851</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:21:25\u001b[0m,\u001b[1;36m851\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_tabular\\models\\node\\node_model.py:111: UserWarning: Ignoring head config because NODE has a specific head which subsets the tree outputs\n",
      "  warnings.warn(\"Ignoring head config because NODE has a specific head which subsets the tree outputs\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:21:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:21:26\u001b[0m,\u001b[1;36m322\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m171\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:21:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">335</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:21:26\u001b[0m,\u001b[1;36m335\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "params = {'eta': 0.06014477612764848, \n",
    "          'max_depth': 5, \n",
    "          'min_child_weight': 14, \n",
    "          'lambda': 0.23378311898486798, \n",
    "          'alpha': 0.00011202585063587642, \n",
    "          'gamma': 0.0009675173727657638, \n",
    "          'subsample': 0.6661968185586394, \n",
    "          'colsample_bytree': 0.871814732691916, \n",
    "          'grow_policy': 'depthwise', \n",
    "          'max_bin': 123}\n",
    "# Train\n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "\n",
    "# 2. Load PyTorch checkpoint (.ckpt)\n",
    "# (Assuming this is a PyTorch Lightning checkpoint)\n",
    "ftt = TabularModel.load_model('ftt')\n",
    "\n",
    "node = TabularModel.load_model('node')\n",
    "\n",
    "in_channels = len(total_feats)\n",
    "\n",
    "out_dim =  len(targets)\n",
    "\n",
    "hidden_channels = [125]*11 + [out_dim]\n",
    "\n",
    "norm_layer = nn.LayerNorm\n",
    "\n",
    "activation_layer = nn.ReLU\n",
    "\n",
    "bias = True\n",
    "\n",
    "dropout = 0.189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8514c9ce-b65e-4268-993e-3131c7f5e640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4c642c-b30c-4eb2-b4be-4cb64e28ddc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 79/79 [00:11<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.2570 | Val Loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 79/79 [00:09<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0539 | Val Loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 79/79 [00:09<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0518 | Val Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 79/79 [00:09<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0506 | Val Loss: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 79/79 [00:09<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0503 | Val Loss: 0.0498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 79/79 [00:09<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0500 | Val Loss: 0.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 79/79 [00:09<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0494 | Val Loss: 0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 79/79 [00:09<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0488 | Val Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:09<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0490 | Val Loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 79/79 [00:09<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0485 | Val Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 79/79 [00:10<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0486 | Val Loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 79/79 [00:11<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0481 | Val Loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 79/79 [00:11<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0482 | Val Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 79/79 [00:11<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0482 | Val Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 79/79 [00:10<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.0479 | Val Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 79/79 [00:10<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.0480 | Val Loss: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 79/79 [00:10<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.0475 | Val Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 79/79 [00:11<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.0477 | Val Loss: 0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 79/79 [00:11<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.0474 | Val Loss: 0.0463\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_14168\\3475746735.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test MSE: 0.0453\n",
      "Test RMSE: 0.2129\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm \n",
    "# Set GPU if available\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use GPU 0 if multiple available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert to PyTorch tensors (no normalization)\n",
    "train_dataset = TensorDataset(\n",
    "    X_train,\n",
    "    Y_train\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    X_val,\n",
    "    Y_val\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    X_test,\n",
    "    Y_test\n",
    ")\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    'input_dim': len(total_feats),\n",
    "    'num_classes': len(targets),\n",
    "    'layer_num': 12,               # Must be even number\n",
    "    'base_outdim': 256,           # Hidden layer size\n",
    "    'k': 6,                       # Multiplicative factor\n",
    "    'virtual_batch_size': 256,     # For Ghost BatchNorm\n",
    "    'drop_rate': 0.05020187264748346,\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.005787836702412583,\n",
    "    'weight_decay': 4.6353263330458526e-07,\n",
    "    'epochs': 50,\n",
    "    'patience': 5\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = DANet(\n",
    "    input_dim=config['input_dim'],\n",
    "    num_classes=config['num_classes'],\n",
    "    layer_num=config['layer_num'],\n",
    "    base_outdim=config['base_outdim'],\n",
    "    k=config['k'],\n",
    "    virtual_batch_size=config['virtual_batch_size'],\n",
    "    drop_rate=config['drop_rate']\n",
    ").to(device)\n",
    "\n",
    "# Multi-target loss function\n",
    "def multi_target_mse(preds, targets):\n",
    "    return torch.mean((preds - targets) ** 2)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                       lr=config['lr'], \n",
    "                       weight_decay=config['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                mode='min',\n",
    "                                                patience=5,\n",
    "                                                factor=0.5)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                         batch_size=config['batch_size'], \n",
    "                         shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                       batch_size=config['batch_size'])\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=config['batch_size'])\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, Y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = multi_target_mse(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            val_loss += multi_target_mse(outputs, Y_batch).item() * X_batch.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            total_loss += multi_target_mse(outputs, Y_batch).item() * X_batch.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "# Final evaluation\n",
    "test_loss = evaluate(model, test_loader)\n",
    "print(f\"\\nTest MSE: {test_loss:.4f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss):.4f}\")\n",
    "\n",
    "# Optional: Save predictions\n",
    "def save_predictions(model, loader, filename):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "    np.save(filename, np.concatenate(all_preds))\n",
    "\n",
    "save_predictions(model, test_loader, 'test_predictions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d3b3ff-2351-4878-ae9b-7144ae0b402c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "danet = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c89cfa44-45e7-437f-b515-0fa06f86df79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_tabular\\models\\node\\config.py:212: UserWarning: `head` and `head_config` is ignored as NODE has a specific head which subsets the tree outputs. Set `head=None` to turn off the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:06\u001b[0m,\u001b[1;36m130\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">163</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:06\u001b[0m,\u001b[1;36m163\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:06\u001b[0m,\u001b[1;36m167\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">184</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: NODEModel              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:06\u001b[0m,\u001b[1;36m184\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: NODEModel              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_tabular\\models\\node\\node_model.py:111: UserWarning: Ignoring head config because NODE has a specific head which subsets the tree outputs\n",
      "  warnings.warn(\"Ignoring head config because NODE has a specific head which subsets the tree outputs\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:06\u001b[0m,\u001b[1;36m218\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m74\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:24\u001b[0m,\u001b[1;36m362\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">605</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:24\u001b[0m,\u001b[1;36m605\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5e4f4241844ba0984e23fe34bd842c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.07585775750291836\n",
      "Restoring states from the checkpoint path at C:\\Users\\joshu\\stacked_models\\.lr_find_bc90b942-824b-4429-ae23-759ca4f119d6.ckpt\n",
      "Restored all states from the checkpoint at C:\\Users\\joshu\\stacked_models\\.lr_find_bc90b942-824b-4429-ae23-759ca4f119d6.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">078</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.07585775750291836</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:37\u001b[0m,\u001b[1;36m078\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.07585775750291836\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">080</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:37\u001b[0m,\u001b[1;36m080\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m74\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:35:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">876</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:35:38\u001b[0m,\u001b[1;36m876\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ NODEBackbone     │  4.2 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     26 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Lambda           │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ NODEBackbone     │  4.2 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     26 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Lambda           │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.2 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 769                                                                                          \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.2 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 16                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 9                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.2 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 769                                                                                          \n",
       "\u001b[1mTotal params\u001b[0m: 4.2 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 16                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 9                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3df07bf2614babb4c1093635becaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:37:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:37:13\u001b[0m,\u001b[1;36m558\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:37:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">559</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:37:13\u001b[0m,\u001b[1;36m559\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_tabular\\utils\\python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE: 0.042143866419792175\n",
      "                         Covariate       MSE\n",
      "0                          Albumin  0.030001\n",
      "1             Alkaline Phosphatase  0.048064\n",
      "2                      Neutrophils  0.036125\n",
      "3                              pO2  0.030278\n",
      "4                        Magnesium  0.061373\n",
      "5                              MCH  0.085020\n",
      "6                  Red Blood Cells  0.015027\n",
      "7                       Creatinine  0.030382\n",
      "8                   Platelet Count  0.061968\n",
      "9                               PT  0.051331\n",
      "10  Alanine Aminotransferase (ALT)  0.020215\n",
      "11                     Base Excess  0.006348\n",
      "12                             MCV  0.085208\n",
      "13                      Hemoglobin  0.005085\n",
      "14                          RDW-SD  0.028423\n",
      "15            Creatine Kinase (CK)  0.030024\n",
      "16                         Glucose  0.076888\n",
      "17                     Bicarbonate  0.042306\n",
      "18                Bilirubin, Total  0.036690\n",
      "19                         INR(PT)  0.041935\n",
      "20                     Lymphocytes  0.040304\n",
      "21                            MCHC  0.072745\n",
      "22                          Sodium  0.034418\n",
      "23                       Anion Gap  0.055517\n",
      "24                             RDW  0.065158\n",
      "25                         Lactate  0.041460\n",
      "26            Calculated Total CO2  0.004414\n",
      "27                       Basophils  0.043321\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 166\u001b[0m\n\u001b[0;32m    162\u001b[0m mse_df_reordered\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(mse_df_reordered)\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m tabular_model\u001b[38;5;241m.\u001b[39msave_model(args\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=encode(targets),\n",
    "    continuous_cols=encode(total_feats),\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=100,\n",
    "    accelerator=\"gpu\"\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = NodeConfig(\n",
    "    num_layers=1,\n",
    "    num_trees=2048,\n",
    "    task=\"regression\",  # or \"regression\"\n",
    "    head=\"LinearHead\",      # Using LinearHead with sigmoid\n",
    "    head_config={\n",
    "        \"layers\": None,    # No additional layers\n",
    "        \"activation\": \"Sigmoid\"  # Sigmoid activation\n",
    "    },\n",
    "    #data_aware_init_batch_size=1000,\n",
    ")\n",
    "\n",
    "# Initialize and train the model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "tabular_model.fit(train=df_train, validation=df_val)\n",
    "\n",
    "Y_test =  torch.tensor(df_test[encode(targets)].values).type(torch.float).cuda()\n",
    "\n",
    "def compute_mse_per_covariate(predictions, targets):\n",
    "    # Ensure predictions and targets are the same shape\n",
    "    assert predictions.shape == targets.shape, \"Shapes of predictions and targets must match\"\n",
    "\n",
    "    # Compute squared error per covariate and average over the batch (dim=0)\n",
    "    mse_per_covariate = torch.mean((predictions - targets) ** 2, dim=0)\n",
    "\n",
    "    return mse_per_covariate  # Returns a tensor of shape (15,)\n",
    "\n",
    "y_pred = tabular_model.predict(df_test)\n",
    "\n",
    "mse_per_covariate = compute_mse_per_covariate(torch.tensor(y_pred.values).type(torch.float).cuda(),Y_test)\n",
    "    # Convert MSE tensor to numpy and pair with column names\n",
    "print(f\"Overall MSE: {mse_per_covariate.mean()}\")\n",
    "with torch.no_grad(): \n",
    "    mse_per_covariate_np = mse_per_covariate.cpu().numpy()  # If using GPU: .cpu().numpy()\n",
    "\n",
    "# Display as a DataFrame for better readability\n",
    "mse_df = pd.DataFrame({\n",
    "    'Covariate': targets,\n",
    "    'MSE': mse_per_covariate_np\n",
    "})\n",
    "\n",
    "order = ['Albumin',\n",
    " 'Alkaline Phosphatase',\n",
    " 'Neutrophils',\n",
    " 'pO2',\n",
    " 'Magnesium',\n",
    " 'MCH',\n",
    " 'Red Blood Cells',\n",
    " 'Creatinine',\n",
    " 'Platelet Count',\n",
    " 'PT',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Base Excess',\n",
    " 'MCV',\n",
    " 'Hemoglobin',\n",
    " 'RDW-SD',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Glucose',\n",
    " 'Bicarbonate',\n",
    " 'Bilirubin, Total',\n",
    " 'INR(PT)',\n",
    " 'Lymphocytes',\n",
    " 'MCHC',\n",
    " 'Sodium',\n",
    " 'Anion Gap',\n",
    " 'RDW',\n",
    " 'Lactate',\n",
    " 'Calculated Total CO2',\n",
    " 'Basophils']\n",
    "\n",
    "mse_df_reordered = mse_df.set_index('Covariate').reindex(order).reset_index()\n",
    "mse_df_reordered\n",
    "\n",
    "print(mse_df_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a55b1b63-cf5d-4ad7-b9c4-bd315d558f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node = tabular_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41366a7e-2daf-45de-b8e4-931a8e0e233d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">721</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m721\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">752</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m752\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m763\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">780</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: FTTransformerModel     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m780\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: FTTransformerModel     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">945</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m945\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:42:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">966</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:42:50\u001b[0m,\u001b[1;36m966\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\joshu\\stacked_models\\saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a6ddf54a5c4aa89cc6c5c73cb0f626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 1.3182567385564076e-05\n",
      "Restoring states from the checkpoint path at C:\\Users\\joshu\\stacked_models\\.lr_find_4667d132-8fe2-4e2a-8b07-f299f671ee54.ckpt\n",
      "Restored all states from the checkpoint at C:\\Users\\joshu\\stacked_models\\.lr_find_4667d132-8fe2-4e2a-8b07-f299f671ee54.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:43:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">870</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3182567385564076e-05</span>. For   \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:43:14\u001b[0m,\u001b[1;36m870\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m1.3182567385564076e-05\u001b[0m. For   \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:43:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">976</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:43:14\u001b[0m,\u001b[1;36m976\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ FTTransformerBackbone │ 42.0 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding2dLayer      │ 13.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead            │ 14.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss               │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ FTTransformerBackbone │ 42.0 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer      │ 13.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead            │ 14.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss               │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 42.0 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 42.0 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 167                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 159                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 42.0 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 42.0 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 167                                                                        \n",
       "\u001b[1mModules in train mode\u001b[0m: 159                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ac9953d09425b8fa446d33b5add97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">422</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:55:32\u001b[0m,\u001b[1;36m422\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">422</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m28\u001b[0m \u001b[1;92m19:55:32\u001b[0m,\u001b[1;36m422\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\envs\\TT_net\\Lib\\site-packages\\pytorch_tabular\\utils\\python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE: 0.03838161379098892\n",
      "                         Covariate       MSE\n",
      "0                          Albumin  0.029157\n",
      "1             Alkaline Phosphatase  0.044323\n",
      "2                      Neutrophils  0.034370\n",
      "3                              pO2  0.027987\n",
      "4                        Magnesium  0.055637\n",
      "5                              MCH  0.075585\n",
      "6                  Red Blood Cells  0.012180\n",
      "7                       Creatinine  0.029232\n",
      "8                   Platelet Count  0.057414\n",
      "9                               PT  0.048430\n",
      "10  Alanine Aminotransferase (ALT)  0.018610\n",
      "11                     Base Excess  0.004358\n",
      "12                             MCV  0.074474\n",
      "13                      Hemoglobin  0.004577\n",
      "14                          RDW-SD  0.024969\n",
      "15            Creatine Kinase (CK)  0.025572\n",
      "16                         Glucose  0.069630\n",
      "17                     Bicarbonate  0.039498\n",
      "18                Bilirubin, Total  0.032843\n",
      "19                         INR(PT)  0.038799\n",
      "20                     Lymphocytes  0.038368\n",
      "21                            MCHC  0.067624\n",
      "22                          Sodium  0.031236\n",
      "23                       Anion Gap  0.049734\n",
      "24                             RDW  0.059353\n",
      "25                         Lactate  0.037328\n",
      "26            Calculated Total CO2  0.002637\n",
      "27                       Basophils  0.040760\n"
     ]
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=encode(targets),\n",
    "    continuous_cols=encode(total_feats),\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=256,\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=99\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    num_heads=2,          # Number of attention heads\n",
    "    num_attn_blocks=8,  # Number of transformer blocks\n",
    "    input_embed_dim=512,\n",
    "    embedding_dropout=0.1,            # Dropout for feature embeddings\n",
    "    attn_dropout=0.1,            # Dropout for attention layers\n",
    "    ff_dropout=0.1,                  # Dropout in feed-forward network\n",
    "    task=\"regression\",                # or \"regression\"\n",
    "    target_range=[(0,1)]*len(targets)\n",
    ")\n",
    "\n",
    "# Initialize and train the model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "tabular_model.fit(train=df_train, validation=df_val)\n",
    "\n",
    "Y_test =  torch.tensor(df_test[encode(targets)].values).type(torch.float).cuda()\n",
    "\n",
    "def compute_mse_per_covariate(predictions, targets):\n",
    "    # Ensure predictions and targets are the same shape\n",
    "    assert predictions.shape == targets.shape, \"Shapes of predictions and targets must match\"\n",
    "\n",
    "    # Compute squared error per covariate and average over the batch (dim=0)\n",
    "    mse_per_covariate = torch.mean((predictions - targets) ** 2, dim=0)\n",
    "\n",
    "    return mse_per_covariate  # Returns a tensor of shape (15,)\n",
    "\n",
    "y_pred = tabular_model.predict(df_test)\n",
    "\n",
    "mse_per_covariate = compute_mse_per_covariate(torch.tensor(y_pred.values).type(torch.float).cuda(), Y_test)\n",
    "print(f\"Overall MSE: {mse_per_covariate.mean()}\")\n",
    "with torch.no_grad(): \n",
    "    mse_per_covariate_np = mse_per_covariate.cpu().numpy()  # If using GPU: .cpu().numpy()\n",
    "\n",
    "# Display as a DataFrame for better readability\n",
    "mse_df = pd.DataFrame({\n",
    "    'Covariate': targets,\n",
    "    'MSE': mse_per_covariate_np\n",
    "})\n",
    "\n",
    "order = ['Albumin',\n",
    " 'Alkaline Phosphatase',\n",
    " 'Neutrophils',\n",
    " 'pO2',\n",
    " 'Magnesium',\n",
    " 'MCH',\n",
    " 'Red Blood Cells',\n",
    " 'Creatinine',\n",
    " 'Platelet Count',\n",
    " 'PT',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Base Excess',\n",
    " 'MCV',\n",
    " 'Hemoglobin',\n",
    " 'RDW-SD',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Glucose',\n",
    " 'Bicarbonate',\n",
    " 'Bilirubin, Total',\n",
    " 'INR(PT)',\n",
    " 'Lymphocytes',\n",
    " 'MCHC',\n",
    " 'Sodium',\n",
    " 'Anion Gap',\n",
    " 'RDW',\n",
    " 'Lactate',\n",
    " 'Calculated Total CO2',\n",
    " 'Basophils']\n",
    "\n",
    "mse_df_reordered = mse_df.set_index('Covariate').reindex(order).reset_index()\n",
    "mse_df_reordered\n",
    "\n",
    "print(mse_df_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb99701-8abb-4835-9c21-135698ab1fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftt = tabular_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c96f3f76-104d-41d3-b294-578e44536dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Stack:\n",
    "    def __init__(self, danet, mlp, ftt, node, xgb_model):\n",
    "        self.danet = danet\n",
    "        self.mlp = mlp\n",
    "        self.ftt = ftt\n",
    "        self.node = node\n",
    "        self.xgb_model = xgb_model\n",
    "        self.MetaModel = MetaModel(5,1)\n",
    "        \n",
    "    def fit(self, X_train, df_train, Y_train):\n",
    "        dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "        train_loader = DataLoader(X_train, \n",
    "                         batch_size=5000, \n",
    "                         shuffle=False)\n",
    "        self.danet.eval()\n",
    "        danet_preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in train_loader:\n",
    "                X_batch = X_batch\n",
    "                preds = self.danet(X_batch)\n",
    "                danet_preds.append(preds)\n",
    "        danet_preds = torch.cat(danet_preds, dim=0)\n",
    "        with torch.no_grad():\n",
    "            mlp_preds = self.mlp(X_train)\n",
    "        ftt_preds = torch.Tensor(self.ftt.predict(df_train[encode(total_feats)]).values)\n",
    "        node_preds = torch.Tensor(self.node.predict(df_train[encode(total_feats)]).values)\n",
    "        xgboost_preds = torch.Tensor(self.xgb_model.predict(dtrain))\n",
    "        combined = torch.stack([ftt_preds, node_preds, xgboost_preds, danet_preds, mlp_preds], dim=2)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        danet_loss = criterion(danet_preds, Y_train).item()\n",
    "        print(f\"danet loss: {danet_loss}\")\n",
    "        \n",
    "        node_loss = criterion(node_preds, Y_train).item()\n",
    "        print(f\"node loss: {node_loss}\")\n",
    "        \n",
    "        xg_loss = criterion(xgboost_preds, Y_train).item()\n",
    "        print(f\"xg loss: {xg_loss}\")\n",
    "        \n",
    "        ftt_loss = criterion(ftt_preds, Y_train).item()\n",
    "        print(f\"ftt loss: {ftt_loss}\")\n",
    "        \n",
    "        mlp_loss = criterion(mlp_preds, Y_train).item()\n",
    "        print(f\"mlp loss: {mlp_loss}\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.MetaModel.parameters(), lr=0.01)\n",
    "        print(combined.shape)\n",
    "        print(Y_train.shape)\n",
    "        for epoch in range(10000):\n",
    "            outputs = self.MetaModel(combined)\n",
    "            outputs = outputs.squeeze(dim=2)\n",
    "            loss = criterion(outputs, Y_train)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if epoch%100 == 0:\n",
    "                print(loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "    def predict(self, X_test, df_test, Y_test):\n",
    "        dtrain = xgb.DMatrix(X_test, label=Y_test)\n",
    "        train_loader = DataLoader(X_test, \n",
    "                         batch_size=5000, \n",
    "                         shuffle=False)\n",
    "        self.danet.eval()\n",
    "        danet_preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch in train_loader:\n",
    "                X_batch = X_batch\n",
    "                preds = self.danet(X_batch)\n",
    "                danet_preds.append(preds)\n",
    "        danet_preds = torch.cat(danet_preds, dim=0)\n",
    "        with torch.no_grad():\n",
    "            mlp_preds = self.mlp(X_test)\n",
    "        ftt_preds = torch.Tensor(self.ftt.predict(df_test[encode(total_feats)]).values)\n",
    "        node_preds = torch.Tensor(self.node.predict(df_test[encode(total_feats)]).values)\n",
    "        xgboost_preds = torch.Tensor(self.xgb_model.predict(dtrain))\n",
    "        combined = torch.stack([ftt_preds, node_preds, xgboost_preds, danet_preds, mlp_preds], dim=2)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        danet_loss = criterion(danet_preds, Y_test).item()\n",
    "        print(f\"danet loss: {danet_loss}\")\n",
    "        \n",
    "        node_loss = criterion(node_preds, Y_test).item()\n",
    "        print(f\"node loss: {node_loss}\")\n",
    "        \n",
    "        xg_loss = criterion(xgboost_preds, Y_test).item()\n",
    "        print(f\"xg loss: {xg_loss}\")\n",
    "        \n",
    "        ftt_loss = criterion(ftt_preds, Y_test).item()\n",
    "        print(f\"ftt loss: {ftt_loss}\")\n",
    "        \n",
    "        mlp_loss = criterion(mlp_preds, Y_test).item()\n",
    "        print(f\"mlp loss: {mlp_loss}\")\n",
    "        print(combined.shape)\n",
    "        print(Y_test.shape)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.MetaModel(combined)\n",
    "        return outputs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1935971-95df-4963-9bf4-f5e8c76f0619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danet loss: 0.04592215642333031\n",
      "node loss: 0.027988247573375702\n",
      "xg loss: 0.03253047168254852\n",
      "ftt loss: 0.03677967190742493\n",
      "mlp loss: 0.03960017114877701\n",
      "torch.Size([10000, 28, 5])\n",
      "torch.Size([10000, 28])\n",
      "0.11069447547197342\n",
      "0.032190680503845215\n",
      "0.03031049855053425\n",
      "0.02877306379377842\n",
      "0.027724435552954674\n",
      "0.027087774127721786\n",
      "0.026723699644207954\n",
      "0.0265158973634243\n",
      "0.026391414925456047\n",
      "0.02631155401468277\n",
      "0.02625749073922634\n",
      "0.026219988241791725\n",
      "0.026193952187895775\n",
      "0.02617613784968853\n",
      "0.026164205744862556\n",
      "0.02615642547607422\n",
      "0.026151500642299652\n",
      "0.02614847756922245\n",
      "0.02614668942987919\n",
      "0.02614566497504711\n",
      "0.026145100593566895\n",
      "0.02614480070769787\n",
      "0.02614464983344078\n",
      "0.02614457719027996\n",
      "0.026144541800022125\n",
      "0.02614452689886093\n",
      "0.026144521310925484\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144517585635185\n",
      "0.026144519448280334\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.0261459331959486\n",
      "0.026144517585635185\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n",
      "0.026144515722990036\n"
     ]
    }
   ],
   "source": [
    "stack = Stack(danet, mlp, ftt, node, xgb_model)\n",
    "stack.fit(X_train, df_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87b3e528-05d9-49f9-8450-24240c7d7329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af937456-3e08-4299-bc88-ff3ea96f53c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danet loss: 0.04533591866493225\n",
      "node loss: 0.042143866419792175\n",
      "xg loss: 0.03779824823141098\n",
      "ftt loss: 0.03838161379098892\n",
      "mlp loss: 0.04083168879151344\n",
      "torch.Size([4640, 28, 5])\n",
      "torch.Size([4640, 28])\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_per_covariate(predictions, targets):\n",
    "    # Ensure predictions and targets are the same shape\n",
    "    assert predictions.shape == targets.shape, \"Shapes of predictions and targets must match\"\n",
    "\n",
    "    # Compute squared error per covariate and average over the batch (dim=0)\n",
    "    mse_per_covariate = torch.mean((predictions - targets) ** 2, dim=0)\n",
    "\n",
    "    return mse_per_covariate  # Returns a tensor of shape (15,)\n",
    "\n",
    "y_pred = stack.predict(X_test.cpu(), df_test, Y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd9c4b24-2947-4b1c-8184-c7acb06487b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d34eba7-5f92-4802-9398-aa8e401beba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE: 0.043800074607133865\n",
      "                         Covariate       MSE\n",
      "0                          Albumin  0.030899\n",
      "1             Alkaline Phosphatase  0.047540\n",
      "2                      Neutrophils  0.038079\n",
      "3                              pO2  0.033059\n",
      "4                        Magnesium  0.064148\n",
      "5                              MCH  0.087763\n",
      "6                  Red Blood Cells  0.015655\n",
      "7                       Creatinine  0.032206\n",
      "8                   Platelet Count  0.064559\n",
      "9                               PT  0.052126\n",
      "10  Alanine Aminotransferase (ALT)  0.021747\n",
      "11                     Base Excess  0.005186\n",
      "12                             MCV  0.089636\n",
      "13                      Hemoglobin  0.005692\n",
      "14                          RDW-SD  0.030120\n",
      "15            Creatine Kinase (CK)  0.031126\n",
      "16                         Glucose  0.078515\n",
      "17                     Bicarbonate  0.045638\n",
      "18                Bilirubin, Total  0.038641\n",
      "19                         INR(PT)  0.042347\n",
      "20                     Lymphocytes  0.044190\n",
      "21                            MCHC  0.077202\n",
      "22                          Sodium  0.035577\n",
      "23                       Anion Gap  0.058295\n",
      "24                             RDW  0.067010\n",
      "25                         Lactate  0.043045\n",
      "26            Calculated Total CO2  0.003498\n",
      "27                       Basophils  0.042903\n"
     ]
    }
   ],
   "source": [
    "def compute_mse_per_covariate(predictions, targets):\n",
    "    # Ensure predictions and targets are the same shape\n",
    "    assert predictions.shape == targets.shape, \"Shapes of predictions and targets must match\"\n",
    "\n",
    "    # Compute squared error per covariate and average over the batch (dim=0)\n",
    "    mse_per_covariate = torch.mean((predictions - targets) ** 2, dim=0)\n",
    "\n",
    "    return mse_per_covariate  # Returns a tensor of shape (15,)\n",
    "\n",
    "mse_per_covariate = compute_mse_per_covariate(y_pred, Y_test.cpu())\n",
    "print(f\"Overall MSE: {mse_per_covariate.mean()}\")\n",
    "with torch.no_grad(): \n",
    "    mse_per_covariate_np = mse_per_covariate.cpu().numpy()  # If using GPU: .cpu().numpy()\n",
    "\n",
    "# Display as a DataFrame for better readability\n",
    "mse_df = pd.DataFrame({\n",
    "    'Covariate': targets,\n",
    "    'MSE': mse_per_covariate_np\n",
    "})\n",
    "\n",
    "order = ['Albumin',\n",
    " 'Alkaline Phosphatase',\n",
    " 'Neutrophils',\n",
    " 'pO2',\n",
    " 'Magnesium',\n",
    " 'MCH',\n",
    " 'Red Blood Cells',\n",
    " 'Creatinine',\n",
    " 'Platelet Count',\n",
    " 'PT',\n",
    " 'Alanine Aminotransferase (ALT)',\n",
    " 'Base Excess',\n",
    " 'MCV',\n",
    " 'Hemoglobin',\n",
    " 'RDW-SD',\n",
    " 'Creatine Kinase (CK)',\n",
    " 'Glucose',\n",
    " 'Bicarbonate',\n",
    " 'Bilirubin, Total',\n",
    " 'INR(PT)',\n",
    " 'Lymphocytes',\n",
    " 'MCHC',\n",
    " 'Sodium',\n",
    " 'Anion Gap',\n",
    " 'RDW',\n",
    " 'Lactate',\n",
    " 'Calculated Total CO2',\n",
    " 'Basophils']\n",
    "\n",
    "mse_df_reordered = mse_df.set_index('Covariate').reindex(order).reset_index()\n",
    "mse_df_reordered\n",
    "\n",
    "print(mse_df_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573cf33-6d55-4947-a32d-b1bd74d04345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f2b62-1f4c-4b1e-851a-765261831927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor1 = torch.randn(100, 5)  # 100 samples, 5 features\n",
    "tensor2 = torch.randn(100, 3)  # 100 samples, 3 features\n",
    "tensor3 = torch.randn(100, 2)  # 100 samples, 2 features\n",
    "\n",
    "# Horizontal stacking (along feature dimension)\n",
    "stacked_tensor = torch.cat([tensor1, tensor2, tensor3], dim=1)\n",
    "print(stacked_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff1499-7268-4346-b511-835f3f0a2472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc595c7-323c-4ab5-8c03-22dc0e420135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3d66d-ac77-47ab-bd7f-500bda0c301a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TT_net",
   "language": "python",
   "name": "tt_net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
